#!/data/data/com.termux/files/usr/bin/python3


# cd /sdcard/acode/my-hugo-paper/assets/ ; python toml2yaml.py

import os
import re
import json
import toml
import yaml
from pathlib import Path
from datetime import datetime, date, timezone

# ===== é…ç½® =====
CONTENT_DIR = "/sdcard/acode/my-hugo-paper/content"
MAPPING_FILE = "/sdcard/acode/my-hugo-paper/assets/toml2yaml_data.json"
URL_PREFIX = "/p/"

# ===== æ˜ å°„æ–‡ä»¶å¤„ç† =====
def ensure_mapping_file_exists():
    mapping_path = Path(MAPPING_FILE)
    if not mapping_path.exists():
        with open(mapping_path, 'w', encoding='utf-8') as f:
            json.dump({}, f, ensure_ascii=False, indent=4)
        print(f"ğŸ“„ åˆ›å»ºæ˜ å°„æ–‡ä»¶: {MAPPING_FILE}")

def load_mapping():
    with open(MAPPING_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_mapping(mapping):
    with open(MAPPING_FILE, 'w', encoding='utf-8') as f:
        json.dump(mapping, f, ensure_ascii=False, indent=4)

# ===== æ–‡ä»¶å”¯ä¸€æ ‡è¯† =====
def get_file_identifier(file_path):
    content_dir = Path(CONTENT_DIR).resolve()
    file_path_abs = Path(file_path).resolve()
    return str(file_path_abs.relative_to(content_dir))

# ===== è¯»å–æ–‡ä»¶çš„weightå’Œdateå€¼ =====
def get_file_sort_keys(file_path):
    """
    è¯»å–å•ä¸ªmdæ–‡ä»¶çš„æ’åºé”®ï¼š(weight, -date_timestamp)
    weighté»˜è®¤æ— ç©·å¤§ï¼Œdateé»˜è®¤æœ€æ—©æ—¶é—´ï¼ˆtimestamp=0ï¼‰
    """
    weight = float('inf')
    date_timestamp = 0  # é»˜è®¤ä¸ºæœ€æ—©æ—¶é—´ï¼ˆ1970-01-01ï¼‰ï¼Œç¡®ä¿æ— dateçš„æ’æœ€å

    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # å…ˆè¯•TOMLæ ¼å¼
    toml_pattern = re.compile(r'^\+\+\+\n(.*?)\n\+\+\+', re.DOTALL)
    toml_match = toml_pattern.search(content)
    if toml_match:
        try:
            data = toml.loads(toml_match.group(1))
            if 'weight' in data:
                weight = data['weight']
            if 'date' in data:
                # è§£ædateä¸ºæ—¶é—´æˆ³ï¼ˆå…¼å®¹dateã€datetimeã€å­—ç¬¦ä¸²ï¼‰
                date_val = data['date']
                if isinstance(date_val, str):
                    # å­—ç¬¦ä¸²è½¬datetimeï¼ˆå¤„ç†Zæ—¶åŒºï¼‰
                    date_obj = datetime.fromisoformat(date_val.replace('Z', '+00:00'))
                elif isinstance(date_val, date) and not isinstance(date_val, datetime):
                    # dateå¯¹è±¡è½¬datetimeï¼ˆé»˜è®¤UTC 0ç‚¹ï¼‰
                    date_obj = datetime.combine(date_val, datetime.min.time(), tzinfo=timezone.utc)
                else:
                    # datetimeå¯¹è±¡ç›´æ¥ä½¿ç”¨
                    date_obj = date_val
                # ç¡®ä¿datetimeæœ‰æ—¶åŒºï¼Œæ— åˆ™é»˜è®¤UTC
                if date_obj.tzinfo is None or date_obj.tzinfo.utcoffset(date_obj) is None:
                    date_obj = date_obj.replace(tzinfo=timezone.utc)
                date_timestamp = date_obj.timestamp()
        except (toml.TomlDecodeError, ValueError):
            pass  # è§£æå¤±è´¥ä¿æŒé»˜è®¤å€¼
    
    # å†è¯•YAMLæ ¼å¼
    else:
        yaml_pattern = re.compile(r'^---\n(.*?)\n---', re.DOTALL)
        yaml_match = yaml_pattern.search(content)
        if yaml_match:
            try:
                data = yaml.safe_load(yaml_match.group(1)) or {}
                if 'weight' in data:
                    weight = data['weight']
                if 'date' in data:
                    # è§£ædateä¸ºæ—¶é—´æˆ³ï¼ˆå…¼å®¹dateã€datetimeã€å­—ç¬¦ä¸²ï¼‰
                    date_val = data['date']
                    if isinstance(date_val, str):
                        # å­—ç¬¦ä¸²è½¬datetimeï¼ˆå¤„ç†Zæ—¶åŒºï¼‰
                        date_obj = datetime.fromisoformat(date_val.replace('Z', '+00:00'))
                    elif isinstance(date_val, date) and not isinstance(date_val, datetime):
                        # dateå¯¹è±¡è½¬datetimeï¼ˆé»˜è®¤UTC 0ç‚¹ï¼‰
                        date_obj = datetime.combine(date_val, datetime.min.time(), tzinfo=timezone.utc)
                    else:
                        # datetimeå¯¹è±¡ç›´æ¥ä½¿ç”¨
                        date_obj = date_val
                    # ç¡®ä¿datetimeæœ‰æ—¶åŒºï¼Œæ— åˆ™é»˜è®¤UTC
                    if date_obj.tzinfo is None or date_obj.tzinfo.utcoffset(date_obj) is None:
                        date_obj = date_obj.replace(tzinfo=timezone.utc)
                    date_timestamp = date_obj.timestamp()
            except (yaml.YAMLError, ValueError):
                pass  # è§£æå¤±è´¥ä¿æŒé»˜è®¤å€¼

    # è¿”å›æ’åºé”®ï¼šå…ˆæŒ‰weightå‡åºï¼Œå†æŒ‰-date_timestampå‡åºï¼ˆå³dateé™åºï¼‰
    return (weight, -date_timestamp)

# ===== è‡ªå®šä¹‰YAMLå¤„ç†å™¨ï¼ˆé”®æ— å¼•å·ï¼Œå­—ç¬¦ä¸²å€¼å•å¼•å·ï¼‰=====
def str_presenter(dumper, data):
    """ä»…å¯¹å­—ç¬¦ä¸²å€¼æ·»åŠ å•å¼•å·ï¼Œé”®ä¿æŒæ— å¼•å·"""
    if '\n' in data:
        return dumper.represent_scalar('tag:yaml.org,2002:str', data, style='|')
    return dumper.represent_scalar('tag:yaml.org,2002:str', data, style="'")

yaml.add_representer(str, str_presenter)

# ===== å¤„ç†æ–‡ä»¶ =====
def process_file(file_path, article_id):
    """æ ¹æ®æ’åºåçš„IDå¤„ç†æ–‡ä»¶ï¼Œç”Ÿæˆå¯¹åº”url"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    new_url = f"{URL_PREFIX}{article_id}/"

    # 1. å¤„ç†TOMLæ ¼å¼
    toml_pattern = re.compile(r'^\+\+\+\n(.*?)\n\+\+\+', re.DOTALL)
    toml_match = toml_pattern.search(content)
    if toml_match:
        try:
            data = toml.loads(toml_match.group(1))
            data['url'] = new_url
            yaml_str = yaml.dump(
                data,
                allow_unicode=True,
                sort_keys=False,
                default_flow_style=False
            )
            yaml_str = re.sub(r"'(.*?)':", r"\1:", yaml_str)
            new_front = f"---\n{yaml_str}---"
            new_content = toml_pattern.sub(new_front, content)
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            print(f"âœ… å¤„ç†å®Œæˆ: {file_path} (ID: {article_id})")
            return
        except toml.TomlDecodeError as e:
            print(f"âŒ TOMLé”™è¯¯ {file_path}: {e}")
            return

    # 2. å¤„ç†YAMLæ ¼å¼
    yaml_pattern = re.compile(r'^---\n(.*?)\n---', re.DOTALL)
    yaml_match = yaml_pattern.search(content)
    if yaml_match:
        try:
            data = yaml.safe_load(yaml_match.group(1)) or {}
            data['url'] = new_url
            yaml_str = yaml.dump(
                data,
                allow_unicode=True,
                sort_keys=False,
                default_flow_style=False
            )
            yaml_str = re.sub(r"'(.*?)':", r"\1:", yaml_str)
            new_front = f"---\n{yaml_str}---"
            new_content = yaml_pattern.sub(new_front, content)
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            print(f"âœ… å¤„ç†å®Œæˆ: {file_path} (ID: {article_id})")
            return
        except yaml.YAMLError as e:
            print(f"âŒ YAMLé”™è¯¯ {file_path}: {e}")
            return

    # 3. æ— Front Matteræ—¶æ·»åŠ 
    new_front = f"---\nurl: '{new_url}'\n---\n"
    new_content = new_front + content
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(new_content)
    print(f"âœ… æ–°å¢Front Matter: {file_path} (ID: {article_id})")

# ===== ä¸»å‡½æ•° =====
def main():
    ensure_mapping_file_exists()
    mapping = load_mapping()

    # 1. ä¸åœ¨contentæ ¹ç›®å½• 2. æ–‡ä»¶åä¸æ˜¯_index.md 3. ä¸åœ¨content/appç›®å½•ä¸‹
    md_files = []
    for file in Path(CONTENT_DIR).glob("**/*.md"):
        if (file.parent.resolve() != Path(CONTENT_DIR).resolve() 
            and file.name != "_index.md" 
            and "content/app" not in str(file.parent.resolve())):
            md_files.append(file)

    if not md_files:
        print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•ç¬¦åˆæ¡ä»¶çš„mdæ–‡ä»¶ï¼ˆéœ€åœ¨å­ç›®å½•ä¸”é_index.mdï¼‰")
        return

    # 2. æ’åºï¼šå…ˆæŒ‰weightå‡åºï¼Œweightç›¸åŒåˆ™æŒ‰dateé™åº
    sorted_files = sorted(md_files, key=lambda x: get_file_sort_keys(x))

    # 3. æŒ‰æ’åºç»“æœåˆ†é…IDå¹¶å¤„ç†æ–‡ä»¶ï¼Œæ›´æ–°æ˜ å°„
    for idx, file_path in enumerate(sorted_files, start=1):
        file_identifier = get_file_identifier(file_path)
        mapping[file_identifier] = str(idx)  # ç”¨æ’åºç´¢å¼•ä½œä¸ºID
        process_file(file_path, str(idx))

    # 4. æ¸…ç†æ˜ å°„ä¸­å·²åˆ é™¤çš„æ–‡ä»¶ï¼ˆå¯é€‰ï¼Œä¿æŒæ˜ å°„æ–‡ä»¶å¹²å‡€ï¼‰
    existing_identifiers = [get_file_identifier(f) for f in md_files]
    cleaned_mapping = {k: v for k, v in mapping.items() if k in existing_identifiers}
    mapping = cleaned_mapping

    # 5. ä¿å­˜æ›´æ–°åçš„æ˜ å°„
    save_mapping(mapping)
    print(f"ğŸ‰ å¤„ç†å®Œæˆï¼å…±å¤„ç† {len(md_files)} ä¸ªæ–‡ä»¶ï¼ˆä»…å­ç›®å½•ï¼Œæ’é™¤æ ¹ç›®å½•åŠ_index.mdï¼‰")

if __name__ == "__main__":
    main()